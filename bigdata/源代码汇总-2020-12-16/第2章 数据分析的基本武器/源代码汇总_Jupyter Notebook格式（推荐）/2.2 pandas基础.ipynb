{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 pandas基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.0 引言**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相较于Numpy来说，Pandas更善于处理二维数据。Pandas主要有两种数据结构：Series和DataFrame。Series类似于通过Numpy产生的一维数组，不同的是Series对象不仅包含数值，还包含一组索引，其创建方式如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "s1 = pd.Series(['丁一', '王二', '张三'])\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 它也是一个一维数据结构，并且对于每个元素都有一个行索引可以用来定位，比如可以通过s1[1]来定位到第二个元素“王二”。\n",
    "print(s1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series单独使用相对较少，pandas主要采用DataFrame数据结构。DataFrame是一种二维表格数据结构，直观一点的话可以将其看作一个Excel表格。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.1 二维数据表格DataFrame的创建**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有三种DataFrame常见的创建方法：通过列表创建、通过字典创建及通过二维数组创建。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) 通过列表创建DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "a = pd.DataFrame([[1, 2], [3, 4], [5, 6]])\n",
    "a  # 在Jupyter Nobebook中，代码框中最后一行代码可以只输入变量名称，即可自动打印，而无需通过print()函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到通过pandas的DataFrame功能生成的二维数组更像我们在Excel中看到二维表格数据，它也有行索引和列索引，其中这里的索引序号都是从0开始的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们还可以自定义其列索引和行索引名称，代码如下：\n",
    "a = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=['date', 'score'], index=['A', 'B', 'C'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过列表生成DataFrame还可以采用如下的方式，演示代码如下：\n",
    "a = pd.DataFrame()  # 创建一个空DataFrame \n",
    "date = [1, 3, 5]\n",
    "score = [2, 4, 6]\n",
    "a['date'] = date\n",
    "a['score'] = score\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) 通过字典创建DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过Pandas创建二维数组 - 字典法\n",
    "b = pd.DataFrame({'a': [1, 3, 5], 'b': [2, 4, 6]}, index=['x', 'y', 'z'])\n",
    "b  # 在Jupyter Notebook编辑器中可以直接输入b进行查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果想让字典键变成行索引，可以通过from_dict的方式来将字典转换成DataFrame，并同时设置orient参数为index，代码如下：\n",
    "c = pd.DataFrame.from_dict({'a': [1, 3, 5], 'b': [2, 4, 6]}, orient=\"index\")\n",
    "print(c)  # 也可以直接输入c进行查看变量结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中orient参数指定字典键对应的方向，默认值为columns，如果不设置成index的话，则还是默认字典键为列索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**补充知识点：通过.T来对表格进行转置**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.DataFrame({'a': [1, 3, 5], 'b': [2, 4, 6]})\n",
    "print(b)\n",
    "print(b.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) 通过二维数组创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.arange(12).reshape(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过Numpy产生的二维数组，也可以创建DataFrame，这里以2.1.3小节里提到的二维数组为例生成一个3行4列的DataFrame，代码如下：\n",
    "import numpy as np\n",
    "d = pd.DataFrame(np.arange(12).reshape(3,4), index=[1, 2, 3], columns=['A', 'B', 'C', 'D'])\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**补充知识点：修改行索引或列索引名称**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame([[1, 2], [3, 4]], columns=['date', 'score'], index=['A', 'B'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果想对索引进行重命名的话，rename()函数的使用方法如下：\n",
    "a = a.rename(index={'A':'阿里', 'B':'腾讯'}, columns={'date':'日期','score':'分数'})\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "补充知识点：这里通过rename之后并没有改变原表格结构，需要重新赋值给a才能改变原表格;或者在rename()中设置inplace参数为True，也能实现真正替换，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame([[1, 2], [3, 4]], columns=['date', 'score'], index=['A', 'B'])\n",
    "a.rename(index={'A':'阿里', 'B':'腾讯'}, columns={'date':'日期','score':'分数'}, inplace=True)  # 另一种方法\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过.values属性，也可以查看此时的index值\n",
    "print(a.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果想给行索引命名，也可以通过如下代码\n",
    "a.index.name = '公司'\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果想把行索引变成某列的内容，可以使用set_index()函数，代码如下：\n",
    "a = a.set_index('日期')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果此时想把行索引换成数字索引，则可以使用reset_index()函数，代码如下：\n",
    "a = a.reset_index()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.2 Excel等文件的读取和写入**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入以下代码，用于读取Excel数据：\n",
    "import pandas as pd\n",
    "data = pd.read_excel('data.xlsx')  # data为DataFrame结构\n",
    "data.head()  # 通过head()可以查看前5行数据，如果写成head(10)则可以查看前10行数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 其中read_excel还可以设定参数，使用方式如下：\n",
    "# pd.read_excel('data.xlsx', sheet_name=0, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入以下代码，用于读取CSV文件：\n",
    "data = pd.read_csv('data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_csv也可以指定参数，使用方式如下：\n",
    "# data = pd.read_csv('data.csv', delimiter=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) 文件写入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先生成一个DataFrame\n",
    "data = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=['A列','B列'])\n",
    "# 将DataFrame导入到Excel当中\n",
    "data.to_excel('data_new.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行之后将在代码所在的文件夹生成一个名为data_new的Excel文件m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上表中，保存的Excel第一列还保留了索引信息，如果想将其删去，可以设置to_excel的参数index为False。to_excel的常见参数有如下一些：sheet_name：数据表名；index：True or False，默认为True保存索引信息，即输出文件的第一列为索引值，选择False的话则忽略索引信息；columns：选择所需要的列；encoding：编码方式。\n",
    "例如要将数据表格导入到Excel文件中并忽略行索引信息，则代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('data_new.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过类似的方式，可以将数据写入到CSV文件当中，代码如下：\n",
    "data.to_csv('data_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和to_excel类似，to_csv也可以设置index、columns、encoding等参数。注意，如果在导出CSV文件事出现了中文乱码现象，且encoding参数设置成“utf-8”失效，则需要将encoding参数设置成“utf_8_sig”，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('演示.csv', index=False, encoding=\"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**补充知识点：文件相对路径与绝对路径**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**相对路径**\n",
    "\n",
    "文件相对路径，即代码所在的文件夹，例如上面案例中写的data.to_excel('data.xlsx')就是在代码所在的文件夹生成Excel文件。\n",
    "\n",
    "**绝对路径**\n",
    "\n",
    "文件绝对路径，就是文件完整的路径名称，例如'E:\\大数据分析\\data.xlsx'就是绝对路径，不过因为在Python中反斜杠“\\”经常有特殊含义，比如说“\\n”表示换行，所以通常建议写绝对路径的时候写两个反斜杠取消可能存在的单个反斜杠的特殊含义，写成'E:\\\\大数据分析\\\\data.xlsx'。\n",
    "\n",
    "除了用两个反斜杠来取消一个反斜杠的特殊意义外，还可以在文件路径的字符串前面加一个r，也可以取消单个反斜杠的特殊含义，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('E:\\\\大数据分析\\\\data.xlsx')  # 绝对路径推荐写法1，此时E盘要有一个名为“大数据分析”的文件夹\n",
    "data.to_excel(r'E:\\大数据分析\\data.xlsx')  # 绝对路径推荐写法2，此时E盘要有一个名为“大数据分析”的文件夹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.3 数据读取与筛选**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先创建一个三行三列的表格，行索引设定为r1、r2和r3，列索引设定为c1、c2和c3，以此为例来演示数据的读取与筛选，代码如下：\n",
    "import pandas as pd\n",
    "data = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]], index=['r1', 'r2', 'r3'], columns=['c1', 'c2', 'c3'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.按照行列进行数据筛选"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) 按照列来选取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过以下代码可以通过列来选取数据，这里先选取单列。\n",
    "a = data['c1']\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此时返回的结果里没有表头信息了，这是因为通过data['c1']选取一列的时候返回的是一个一维序列结构的类，也可以通过如下代码返回一个二维的表格数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = data[['c1']]\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若要选取多列，则需要在中括号[]中给个列表，比如要读取c1和c3列，则可以写为data[['c1', 'c3']]。这里需要特别注意的是，必须是一个列表，而不能是data['c1', 'c3']，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = data[['c1', 'c3']]\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) 按照行来选取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选取第2到3行的数据，注意序号从0开始，左闭右开\n",
    "a = data[1:3] \n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而pandas推荐使用iloc方法来根据行的序号进行行选取，它是根据行序号选取的另一种方法，pandas觉得这样更加直观，不会像data[1:3]可能会引起混淆，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = data.iloc[1:3]\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而且如果要选取单行的话，就必须得用iloc了，比如选择倒数第一行，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = data.iloc[-1]\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了通过行的序号选取外，还可以通过loc方法根据行的名称来进行选取，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data.loc[['r2', 'r3']]\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有的时候如果行数很多，可以通过head()方法来选取前5行，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = data.head()\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里因为只创建了3行数据，所以通过data.head()会把全部数据都取到，如果只想取前两行的数据，可以写成data.head(2)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) 按照区块来选取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果想选取某几行的某几列，则可以通过如下代码来实现，比如获得c1和c3列的前二行。\n",
    "a = data[['c1', 'c3']][0:2]  # 也可写成data[0:2][['c1', 'c3']]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在实战中，通常采用iloc和列选取混合的方式来选取特定的区块或值，代码如下：\n",
    "b = data.iloc[0:2][['c1', 'c3']] \n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果要选取单个的值，那么该方法就更有优势，比如选取c3列第一行的信息，就不能写成data['c3'][0]或data[0]['c3']了。下面的写法则比较清晰，iloc[0]先选取第一行，然后再选取c3列。\n",
    "c = data.iloc[0]['c3']\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 也可以通过iloc和loc方法来同时选择行和列，代码如下：\n",
    "d = data.loc[['r1', 'r2'], ['c1', 'c3']]  \n",
    "e = data.iloc[0:2, [0, 2]]  \n",
    "print(d)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 还有一个ix选择区域的方法，它也可以同时选择行和列，而且里面的内容不像loc或者iloc必须为字符索引或者数字索引，代码如下：\n",
    "f = data.ix[0:2, ['c1', 'c3']]\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.按照特定条件筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在方括号里还可以通过判断条件来过滤行，比如选取c1列数字大于1的行，代码如下：\n",
    "a = data[data['c1'] > 1]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果有多个筛选条件，则可以通过“&”符号（表示“且”）或“|”（表示“或”）连接，比如这边筛选，c1列数字大于1且c2列数字小于8的行，代码如下，注意要记得加判断条件两旁的小括号。\n",
    "b = data[(data['c1'] > 1) & (data['c2'] < 8)]\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.数据整体情况查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过表格的shape属性，可以查看表格整体的行数和列数，在表格数据量较大的时候能快速了解表格的行数和列数。\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过表格的describe()函数可以快速的查看表格每一列的数量、平均值、标准差、最小值、25分位数、50分位数、75分位数、最大值等信息，代码如下：\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过value_counts()函数则可以快速的查看某一列都有什么数据，以及该数据出现的频次，代码如下：\n",
    "data['c1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.数据运算、排序与删除"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) 数据运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从已有的列中，通过数据运算创造一个新的一列，代码如下：\n",
    "data['c4'] = data['c3'] - data['c1']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) 数据排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过sort_values()可以根据列对数据进行排序，比如要对c2列进行降序排序，代码如下：\n",
    "a = data.sort_values(by='c2', ascending=False) \n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 其实如果是按列筛选，我们也可以直接写成如下代码，不用写“by=”，效果一样：\n",
    "a = data.sort_values('c2', ascending=False)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此外，通过sort_index()可以根据行索引进行排序，如按行索引进行升序排列，代码如下：\n",
    "a = a.sort_index()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) 数据删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例如删除c1列的数据，代码如下：\n",
    "a = data.drop(columns='c1')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除多列的数据，比如c1和c3列，可以通过列表的方式将所需删除的列声明，代码如下：\n",
    "b = data.drop(columns=['c1', 'c3'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果要删除行数据，比如删去第一行和第三行的数据，代码如下：\n",
    "c = data.drop(index=['r1','r3'])\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意这里要输入行索引的名称而不是数字序号，不过如果行索引名称本来就是数字，那么可以输入对应数字。上面删除数据后又赋值给新的变量不会改变原来表格data的结构，如果想改变原来表格的结构，可以令inplace参数为True，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(index=['r1','r3'], inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.4 数据表拼接**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设有如下两个DataFrame表格，需要对它们进行合并：\n",
    "import pandas as pd\n",
    "df1 = pd.DataFrame({'公司': ['万科', '阿里', '百度'], '分数': [90, 95, 85]})\n",
    "df2 = pd.DataFrame({'公司': ['万科', '阿里', '京东'], '股价': [20, 180, 30]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) merge()函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge()函数根据一个或多个键将不同表格中的行连接起来，示例如下：\n",
    "df3 = pd.merge(df1, df2)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到通过merge()函数直接选取相同的列名（“公司”这一列）进行合并，而且默认选取的是两种表共有的列内容（万科、阿里），有的时候如果相同的列名不止一个，可以通过on参数指定按照哪一列进行合并，代码如下：\n",
    "df3 = pd.merge(df1, df2, on='公司')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "默认的合并其实是取交集（inner连接），也即取两表共有的内容，如果想取并集（outer连接），也即选取两表所有的内容，可以设置how参数，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.merge(df1, df2, how='outer')\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想保留左表全部内容，而对右表不太在意的话，可以将how参数设置为left："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.merge(df1, df2, how='left')\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同理，如果想保留右表全部内容，而对左表不太在意的话，可以将how参数设置为right。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果想根据行索引进行合并，可以通过设置left_index和right_index参数，代码如下：\n",
    "df3 = pd.merge(df1, df2, left_index=True, right_index=True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**补充知识点：根据行索引合并的join()函数**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过join()函数也可以根据行索引进行表格合并。join(）函数也是一种数据表拼接的常见函数，它是通过行索引进行合并，演示代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df1.join(df2, lsuffix='_x', rsuffix='_y')\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意在通过join()函数进行拼接的时候，两张表格中不能有名字相同的列名，如果存在的话，则需要设置lsuffix参数（左表同名列的后缀，suffix的中文翻译就是后缀的意思，l表示left）和rsuffix参数（右表同名列的后缀，这里的r表示right），没有相同列名的话，则可以直接写df1.join(df2)，相对于merge()函数写法较为简洁一些。\n",
    "\n",
    "实战中可以只记merge()函数的用法，这里讲解join()函数的目的是为了看到别人用join()函数的时候能够理解。该知识点在14.3.3小节进行数据表合并的时候便有应用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) concat()函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 默认情况下，axis=0，按行方向进行连接。\n",
    "df3 = pd.concat([df1,df2], axis=0)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此时行索引为原来两张表各自的索引，如果想重置索引，可以使用6.2.1小节讲过的reset_index()方法将索引重置，或者在concat()中设置ignore_index=True，忽略原有索引，按新数字索引进行排序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果想按列方向进行连接，可以设置axis参数为1。\n",
    "df3 = pd.concat([df1,df2],axis=1)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) append()函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append()函数可以说concat()函数的简化版，效果和pd.concat([df1,df2]) 类似，代码如下：\n",
    "df3 = df1.append(df2)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append()函数还有个常用的功能，和列表.append()一样，可用来新增元素，代码如下：\n",
    "df3 = df1.append({'公司': '腾讯', '分数': '90'}, ignore_index=True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据表拼接的相关知识点将在14.3.2节电影数据拼接时会有用到。\n",
    "\n",
    "除了上面的知识点外，在11.2小节我们还会讲解如何通过pandas库处理重复值、缺失值及异常值，在14.3.3小节讲解数据透视表函数pivot_table()函数，以及在14.3小节的补充知识点讲解pandas库的groupby()函数相关知识点。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}